---
phase: 03-ccr-integration
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/llm/agent.js
  - src/llm/prompts.js
  - src/index.js
autonomous: true

must_haves:
  truths:
    - "LLM wrapper exposes executeLLMTask function for command handlers"
    - "SDK configured for non-interactive mode (permissionMode: acceptEdits)"
    - "ANTHROPIC_API_KEY read from environment (not hardcoded)"
    - "Prompt templates available for milestone creation tasks"
  artifacts:
    - path: "src/llm/agent.js"
      provides: "Agent SDK wrapper with CI-safe configuration"
      exports: ["executeLLMTask", "executeLLMTaskWithRetry"]
      min_lines: 40
    - path: "src/llm/prompts.js"
      provides: "Prompt template helpers"
      exports: ["createMilestonePrompt"]
      min_lines: 10
  key_links:
    - from: "src/llm/agent.js"
      to: "@anthropic-ai/claude-agent-sdk"
      via: "import { query }"
      pattern: "import.*query.*from.*claude-agent-sdk"
    - from: "src/llm/agent.js"
      to: "process.env.ANTHROPIC_API_KEY"
      via: "environment variable read"
      pattern: "ANTHROPIC_API_KEY"
---

<objective>
Create LLM integration layer with Agent SDK wrapper configured for CI-safe, non-interactive execution.

Purpose: Provide a clean API for command handlers to execute LLM tasks without direct SDK coupling. Wrapper encapsulates CI-specific configuration (permissionMode, allowed tools, error handling) and provides retry logic for robustness.

Output: Agent wrapper module (src/llm/agent.js) with executeLLMTask function, prompt template helpers (src/llm/prompts.js), ready for command handler integration in later phases.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ccr-integration/03-RESEARCH.md

# Prior plan context
@.planning/phases/03-ccr-integration/03-01-SUMMARY.md

# Files to modify
@src/index.js
</context>

<tasks>

<task type="auto">
  <name>Create Agent SDK wrapper module</name>
  <files>src/llm/agent.js</files>
  <action>
Create `src/llm/agent.js` with two exported functions based on RESEARCH.md patterns:

**Function 1: executeLLMTask(prompt, options)**
- Import `query` from `@anthropic-ai/claude-agent-sdk`
- Set default options for CI environment:
  - `model: "claude-sonnet-4-5-20250929"` (pin specific model)
  - `permissionMode: "acceptEdits"` (auto-approve file edits in CI, no prompts)
  - `allowedTools: ["Read", "Write", "Bash", "Glob", "Grep"]` (enable file and command tools)
  - `maxTurns: 50` (reasonable limit for command execution)
- Process message stream asynchronously using `for await`
- Collect text blocks from assistant messages
- Return `{ success: true, output: messages.join("\n") }` on success
- Catch errors and return `{ success: false, error: error.message }`

**Function 2: executeLLMTaskWithRetry(prompt, options, maxRetries = 3)**
- Wrapper around executeLLMTask with exponential backoff
- Retry on rate limit (429) or overloaded (529) errors
- Don't retry on authentication errors (401)
- Detect errors in message content (SDK may return errors as text, not exceptions)
- Exponential backoff: 2^attempt seconds between retries

**Why permissionMode: acceptEdits**: Default SDK behavior is interactive prompts for file changes. In CI, there's no TTY, so we must auto-approve. This satisfies CCR-07 (non-interactive mode).

**Why error detection in message content**: Research (03-RESEARCH.md Pitfall 6) notes that current SDK may return API errors as text in message stream instead of throwing exceptions. Defensive check prevents silent failures.

**Reference**: 03-RESEARCH.md sections "Pattern 1: Agent SDK Initialization", "Code Examples: Basic Agent SDK Usage in GitHub Action", and "Error Handling Pattern".
  </action>
  <verify>
```bash
# Verify module exists and has correct exports
test -f src/llm/agent.js && echo "Module created"
grep -q "export.*executeLLMTask" src/llm/agent.js && echo "Main function exported"
grep -q "export.*executeLLMTaskWithRetry" src/llm/agent.js && echo "Retry function exported"

# Verify SDK import
grep -q "import.*query.*from.*claude-agent-sdk" src/llm/agent.js && echo "SDK imported"

# Verify CI-safe configuration
grep -q "permissionMode.*acceptEdits" src/llm/agent.js && echo "Non-interactive mode configured"
grep -q "allowedTools" src/llm/agent.js && echo "Tools configured"

# Verify error handling
grep -q "try.*catch" src/llm/agent.js && echo "Error handling present"
```
  </verify>
  <done>src/llm/agent.js exists with executeLLMTask and executeLLMTaskWithRetry exports, imports Agent SDK query function, configures permissionMode: acceptEdits, includes error handling and retry logic</done>
</task>

<task type="auto">
  <name>Create prompt template helpers</name>
  <files>src/llm/prompts.js</files>
  <action>
Create `src/llm/prompts.js` with prompt template functions for GSD commands:

**Function: createMilestonePrompt(args)**
- Accepts args object with milestone specification
- Returns formatted prompt string for milestone creation
- Template should include:
  - Clear instruction to create milestone planning documents
  - Specification data (JSON.stringify(args, null, 2))
  - Instruction to review codebase before creating files
  - Expected outputs: PROJECT.md, ROADMAP.md, STATE.md in .github/planning/

Example structure:
```javascript
export function createMilestonePrompt(args) {
  return `
Create a new GSD milestone based on this specification:
${JSON.stringify(args, null, 2)}

Instructions:
1. Review the existing codebase structure
2. Create planning documents in .github/planning/:
   - PROJECT.md with milestone context
   - ROADMAP.md with phase structure
   - STATE.md with milestone status
3. Follow GSD planning standards

Respond with file contents and any questions needed for requirements gathering.
  `.trim();
}
```

**Why template functions**: Separates prompt engineering from execution logic. Makes prompts testable and reusable across command handlers. Easier to iterate on prompt quality without touching agent wrapper.

**Note**: Additional prompt templates (for other GSD commands) will be added in later phases (Phase 5+). This plan creates the module and adds the first template.
  </action>
  <verify>
```bash
# Verify module exists and exports
test -f src/llm/prompts.js && echo "Module created"
grep -q "export.*createMilestonePrompt" src/llm/prompts.js && echo "Template function exported"

# Verify prompt structure
grep -q "JSON.stringify" src/llm/prompts.js && echo "Prompt includes args serialization"
grep -q "planning" src/llm/prompts.js && echo "Prompt mentions planning docs"
```
  </verify>
  <done>src/llm/prompts.js exists with createMilestonePrompt export, template includes milestone spec and planning doc instructions</done>
</task>

<task type="auto">
  <name>Add LLM module placeholder integration</name>
  <files>src/index.js</files>
  <action>
Update `src/index.js` to import the LLM wrapper (but don't execute yet - that's for Phase 5):

Add import at top of file:
```javascript
import { executeLLMTaskWithRetry } from "./llm/agent.js";
import { createMilestonePrompt } from "./llm/prompts.js";
```

Add comment in the TODO section (line 53, after config loading):
```javascript
// TODO: Execute command logic in later phases (Phase 4+)
// LLM integration ready - executeLLMTaskWithRetry and createMilestonePrompt available
// Example: const result = await executeLLMTaskWithRetry(createMilestonePrompt(sanitizedArgs));
```

**Why add imports now**: Validates that modules are correctly structured and importable. Ensures no circular dependency issues. Provides clear hook point for Phase 5 command execution.

**Why not execute yet**: Phase 3 focuses on LLM integration infrastructure. Phase 5 (Milestone Creation Workflow) will implement the actual command execution logic. This task proves the integration is ready without changing behavior.

**Note**: Do NOT modify action.yml to add ANTHROPIC_API_KEY input yet - that's in the next plan (03-03) which includes end-to-end verification.
  </action>
  <verify>
```bash
# Verify imports added
grep -q "import.*executeLLMTaskWithRetry.*from.*llm/agent" src/index.js && echo "Agent wrapper imported"
grep -q "import.*createMilestonePrompt.*from.*llm/prompts" src/index.js && echo "Prompts imported"

# Verify TODO comment updated
grep -q "LLM integration ready" src/index.js && echo "Integration placeholder added"

# Verify no execution yet (should still have original TODO line)
grep -q "TODO: Execute command logic in later phases" src/index.js && echo "Execution deferred to Phase 5"

# Verify code still runs (basic syntax check)
node --check src/index.js && echo "Syntax valid"
```
  </verify>
  <done>src/index.js imports LLM wrapper and prompt functions, includes integration placeholder comment, no execution logic added yet, syntax validation passes</done>
</task>

</tasks>

<verification>
Run all task verification commands. Success criteria:
- src/llm/agent.js exists with executeLLMTask and executeLLMTaskWithRetry exports
- Agent wrapper imports Agent SDK query function
- Configuration includes permissionMode: acceptEdits (non-interactive)
- Error handling and retry logic present
- src/llm/prompts.js exists with createMilestonePrompt export
- src/index.js imports LLM modules without executing them
- All files pass Node.js syntax validation (node --check)
</verification>

<success_criteria>
**Requirements satisfied**: CCR-03 (environment variable config), CCR-04 (API key from environment), CCR-05 (SDK handles LLM calls), CCR-07 (non-interactive mode)

**Observable behaviors**:
1. LLM wrapper can be imported and called from command handlers
2. SDK configured for CI-safe execution (no prompts, auto-approve edits)
3. Environment variable pattern established (ANTHROPIC_API_KEY)
4. Prompt templates separate from execution logic

**Files created**:
- src/llm/agent.js: Agent SDK wrapper with retry logic
- src/llm/prompts.js: Prompt template helpers

**Files modified**:
- src/index.js: Added LLM module imports

**Ready for next plan**: LLM integration ready for end-to-end verification with ANTHROPIC_API_KEY input (Plan 03-03).
</success_criteria>

<output>
After completion, create `.planning/phases/03-ccr-integration/03-02-SUMMARY.md` with:
- Performance metrics
- Module structure and exports
- Configuration settings (model, permissionMode, tools)
- Any deviations from plan
- Integration verification results
</output>
