---
phase: 10-test-infrastructure
plan: 05
type: execute
wave: 3
depends_on: ["10-02", "10-03", "10-04"]
files_modified:
  - src/milestone/index.test.js
  - src/milestone/requirements.test.js
  - src/milestone/planning-docs.test.js
  - src/errors/handler.test.js
  - src/lib/config.test.js
  - src/llm/config-generator.test.js
autonomous: true

must_haves:
  truths:
    - "Milestone workflow orchestrator tested end-to-end"
    - "Requirements gathering tested with comment parsing"
    - "Planning docs generation tested with file system mocking"
    - "Error handler tested with both auth and technical errors"
  artifacts:
    - path: "src/milestone/index.test.js"
      provides: "Tests for executeMilestoneWorkflow and parseMilestoneNumber"
      min_lines: 60
    - path: "src/milestone/requirements.test.js"
      provides: "Tests for getNewComments, parseUserAnswers, formatRequirementsQuestions, parseAnswersFromResponse"
      min_lines: 80
    - path: "src/milestone/planning-docs.test.js"
      provides: "Tests for createPlanningDocs and markdown generators"
      min_lines: 70
    - path: "src/errors/handler.test.js"
      provides: "Tests for withErrorHandling wrapper"
      min_lines: 50
    - path: "src/lib/config.test.js"
      provides: "Tests for loadConfig"
      min_lines: 30
    - path: "src/llm/config-generator.test.js"
      provides: "Tests for generateCCRConfig"
      min_lines: 40
  key_links:
    - from: "src/milestone/index.test.js"
      to: "src/milestone/requirements.js"
      via: "workflow integration"
      pattern: "import.*requirements"
---

<objective>
Create tests for workflow orchestrators and remaining utility modules.

Purpose: Complete test coverage for milestone workflows, requirements gathering, planning document generation, error handling, and configuration modules.

Output: Test files covering the remaining 6 modules with comprehensive integration scenarios.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/10-test-for-each-service-method-feature-and-flow/10-RESEARCH.md
@.planning/phases/10-test-for-each-service-method-feature-and-flow/10-02-SUMMARY.md
@.planning/phases/10-test-for-each-service-method-feature-and-flow/10-03-SUMMARY.md
@.planning/phases/10-test-for-each-service-method-feature-and-flow/10-04-SUMMARY.md
@src/milestone/index.js
@src/milestone/requirements.js
@src/milestone/planning-docs.js
@src/errors/handler.js
@src/lib/config.js
@src/llm/config-generator.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create milestone/index.js and requirements.js tests</name>
  <files>src/milestone/index.test.js, src/milestone/requirements.test.js</files>
  <action>
  **milestone/index.test.js:**

  ```javascript
  import { describe, it, expect, vi, beforeEach } from 'vitest';

  // Mock dependencies
  vi.mock('./requirements.js', () => ({
    getNewComments: vi.fn(),
    parseUserAnswers: vi.fn(),
    formatRequirementsQuestions: vi.fn(),
    DEFAULT_QUESTIONS: []
  }));

  vi.mock('./planning-docs.js', () => ({
    createPlanningDocs: vi.fn()
  }));

  vi.mock('../lib/github.js', () => ({
    postComment: vi.fn(),
    getWorkflowRunUrl: vi.fn(() => 'https://example.com/run/123')
  }));

  vi.mock('../git/branches.js', () => ({
    createMilestoneBranch: vi.fn()
  }));

  vi.mock('@actions/core', () => ({
    info: vi.fn(),
    warning: vi.fn()
  }));
  ```

  **parseMilestoneNumber tests:**
  - Parses "--milestone 1"
  - Parses "--milestone=1"
  - Parses "-m 1"
  - Parses "-m=1"
  - Parses standalone "1"
  - Defaults to 1 when empty
  - Throws for non-numeric

  **executeMilestoneWorkflow tests (integration):**
  - Calls requirements gathering
  - Creates planning docs
  - Posts summary comment
  - Returns complete status

  **requirements.test.js:**

  ```javascript
  import { describe, it, expect, vi, beforeEach } from 'vitest';
  import * as github from '@actions/github';

  vi.mock('@actions/github', () => ({
    getOctokit: vi.fn(() => ({
      paginate: vi.fn(),
      rest: { issues: { listComments: vi.fn() } }
    }))
  }));

  vi.mock('@actions/core', () => ({
    getInput: vi.fn(() => 'mock-token')
  }));
  ```

  **DEFAULT_QUESTIONS tests:**
  - Contains 4 questions
  - Each has id, question, required fields
  - scope and features are required
  - constraints and timeline are optional

  **getNewComments tests:**
  - Returns comments newer than lastProcessedId
  - Filters out github-actions[bot] comments
  - Filters out Bot type users
  - Sorts by ID ascending

  **parseUserAnswers tests:**
  - Extracts user, body, timestamp from comments
  - Skips bot comments
  - Returns array of answer objects

  **formatRequirementsQuestions tests:**
  - Formats questions with status icons
  - Shows :white_check_mark: for answered
  - Shows :hourglass: for pending
  - Includes existing answers in blockquotes

  **parseAnswersFromResponse tests:**
  - Parses Q: prefix format
  - Parses paragraph-order fallback
  - Skips headers and list markers
  - Handles partial answers
  </action>
  <verify>Run `npm test -- src/milestone/index.test.js src/milestone/requirements.test.js --run` - all tests pass</verify>
  <done>Milestone orchestrator and requirements gathering tested</done>
</task>

<task type="auto">
  <name>Task 2: Create planning-docs.js and handler.js tests</name>
  <files>src/milestone/planning-docs.test.js, src/errors/handler.test.js</files>
  <action>
  **planning-docs.test.js:**

  ```javascript
  import { describe, it, expect, vi, beforeEach } from 'vitest';

  // Mock fs/promises
  vi.mock('node:fs/promises', () => ({
    default: {
      mkdir: vi.fn(),
      writeFile: vi.fn()
    }
  }));

  vi.mock('@actions/core', () => ({
    info: vi.fn()
  }));
  ```

  **createPlanningDocs tests:**
  - Creates directory structure
  - Creates PROJECT.md
  - Creates STATE.md
  - Creates ROADMAP.md
  - Returns files map with paths and purposes

  **generateProjectMarkdown tests:**
  - Includes milestone number and title
  - Includes goal and scope
  - Formats features as bullet list
  - Handles missing optional fields
  - Includes requirements summary table

  **generateStateMarkdown tests:**
  - Includes milestone number
  - Includes phase status table
  - Includes requirements gathering status
  - Includes workflow timestamps

  **generateRoadmapMarkdown tests:**
  - Includes total phases count
  - Formats phase structure
  - Includes execution order
  - Handles empty phases array

  **handler.test.js:**

  ```javascript
  import { describe, it, expect, vi, beforeEach } from 'vitest';
  import { AuthorizationError } from '../auth/errors.js';

  vi.mock('@actions/core', () => ({
    setFailed: vi.fn(),
    info: vi.fn()
  }));

  vi.mock('../lib/github.js', () => ({
    postComment: vi.fn(),
    getWorkflowRunUrl: vi.fn(() => 'https://example.com/run/123')
  }));

  vi.mock('./formatter.js', () => ({
    formatErrorComment: vi.fn((err) => `Error: ${err.message}`)
  }));
  ```

  **withErrorHandling tests:**
  - Returns success: true on successful operation
  - Spreads operation result into return
  - Calls setFailed on error
  - Posts formatted error comment for technical errors
  - Posts userMessage for AuthorizationError (not formatted)
  - Returns success: false with error message
  - Returns isAuthorizationError: true for auth errors
  </action>
  <verify>Run `npm test -- src/milestone/planning-docs.test.js src/errors/handler.test.js --run` - all tests pass</verify>
  <done>Planning docs generation and error handling tested</done>
</task>

<task type="auto">
  <name>Task 3: Create config.js and config-generator.js tests</name>
  <files>src/lib/config.test.js, src/llm/config-generator.test.js</files>
  <action>
  **config.test.js:**

  Read src/lib/config.js first to understand its structure, then create tests:

  ```javascript
  import { describe, it, expect, vi, beforeEach } from 'vitest';

  vi.mock('@actions/core', () => ({
    getInput: vi.fn(),
    info: vi.fn()
  }));
  ```

  **loadConfig tests:**
  - Returns default config when no overrides
  - Uses GitHub token from input or env
  - Includes default paths
  - Includes default phases
  - Includes default status labels

  **config-generator.test.js:**

  ```javascript
  import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
  import fs from 'fs';
  import os from 'os';
  import path from 'path';

  // Mock fs module
  vi.mock('fs', () => ({
    default: {
      existsSync: vi.fn(),
      mkdirSync: vi.fn(),
      writeFileSync: vi.fn()
    }
  }));

  // Mock os module
  vi.mock('os', () => ({
    default: {
      homedir: vi.fn(() => '/mock/home')
    }
  }));
  ```

  **generateCCRConfig tests:**
  - Creates config directory if not exists
  - Writes config.json to ~/.claude-code-router/
  - Includes NON_INTERACTIVE_MODE: true
  - Includes Providers array with openrouter
  - Includes Router with default model
  - Throws if OPENROUTER_API_KEY not set
  - Uses CCR_DEFAULT_MODEL env var when provided

  Mock process.env for tests:
  ```javascript
  beforeEach(() => {
    process.env.OPENROUTER_API_KEY = 'test-key';
    process.env.CCR_DEFAULT_MODEL = 'test-model';
  });

  afterEach(() => {
    delete process.env.OPENROUTER_API_KEY;
    delete process.env.CCR_DEFAULT_MODEL;
  });
  ```
  </action>
  <verify>Run `npm test -- src/lib/config.test.js src/llm/config-generator.test.js --run` - all tests pass</verify>
  <done>Config loading and CCR config generation tested</done>
</task>

</tasks>

<verification>
1. `npm test -- --run` runs all 18+ test files
2. `npm run test:coverage` shows >80% overall coverage
3. All workflow orchestrators have integration test coverage
4. Error handling paths verified (auth errors vs technical errors)
5. File system operations mocked correctly
</verification>

<success_criteria>
- 6 test files created for remaining modules
- Milestone workflow orchestrator tested end-to-end
- Requirements gathering tested with comment parsing
- Planning docs tested with markdown generation
- Error handler tested for both error types
- Config modules tested with env var handling
- All tests pass on `npm test -- --run`
- Overall coverage >80%
</success_criteria>

<output>
After completion, create `.planning/phases/10-test-for-each-service-method-feature-and-flow/10-05-SUMMARY.md`
</output>
